import os
import json
import sys
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
import shutil

sys.stdout.reconfigure(encoding='utf-8')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# JSON ë¡œë“œ â†’ LangChain ë¬¸ì„œ ë³€í™˜
def load_movie_json(json_path: str) -> list[Document]:
    if not os.path.exists(json_path):
        raise FileNotFoundError(f"{json_path} íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    with open(json_path, "r", encoding="utf-8") as f:
        movies = json.load(f)

    docs = []
    seen_titles = set()
    for movie in movies:
        title = movie.get("title", "ì œëª© ì—†ìŒ")
        overview = movie.get("overview", "")
        year = movie.get("release_year", "ì—°ë„ ì—†ìŒ")
        moods = movie.get("mood_labels", [])
        unique_key = f"{title} ({year})"
    
        if unique_key in seen_titles:
            continue  # ì¤‘ë³µì€ ê±´ë„ˆëœ€
        seen_titles.add(unique_key)
        
        # âœ… ë¶„ìœ„ê¸° íƒœê·¸ë¥¼ page_contentì—ë„ í¬í•¨
        text = (
            f"[ì œëª©] {title} ({year})\n"
            f"[ì¤„ê±°ë¦¬] {overview}\n"
            f"[ë¶„ìœ„ê¸° íƒœê·¸] {', '.join(moods)}"
        )

        # âœ… ë°˜ë“œì‹œ metadataì— mood_labels í¬í•¨
        docs.append(Document(
            page_content=text,
            metadata={
                "title": title,
                "year": year,
                "mood_labels": ", ".join(moods)
            }
        ))

    print(f"âœ… ì´ {len(docs)}ê°œ ì˜í™” ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
    return docs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë²¡í„°DB ìƒì„± ë° í…ŒìŠ¤íŠ¸
def prepare_chroma_movie_db(json_path: str, persist_dir: str):
    if os.path.exists(persist_dir):
        print(f"ðŸ§¹ ê¸°ì¡´ ë²¡í„° DB ì œê±°: {persist_dir}")
        shutil.rmtree(persist_dir)  # ðŸ’¥ DB ì´ˆê¸°í™”
    print("ðŸ“¦ ê³ ì„±ëŠ¥ ìž„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... (KoSBERT)")
    embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-sts")

    print("ðŸ“„ ì˜í™” ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    movie_docs = load_movie_json(json_path)

    print("ðŸ’¾ ë²¡í„° DBì— ì €ìž¥ ì¤‘...")
    vector_db = Chroma.from_documents(
        documents=movie_docs,
        embedding=embedding_model,
        persist_directory=persist_dir
    )
    print(f"ðŸŽ‰ ë²¡í„° DB ì €ìž¥ ì™„ë£Œ: {persist_dir} (ì´ {len(movie_docs)}ê°œ ë¬¸ì„œ)")

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    print("\nðŸ” [í…ŒìŠ¤íŠ¸ ê²€ìƒ‰] 'ìž”ìž”í•˜ê³  ì¸ìƒì„ ë˜ëŒì•„ë³´ê²Œ í•˜ëŠ” ì˜í™”'")
    vector_db = Chroma(
        embedding_function=embedding_model,
        persist_directory=persist_dir
    )
    query = "ìž”ìž”í•˜ê³  ì¸ìƒì„ ë˜ëŒì•„ë³´ê²Œ í•˜ëŠ” ì˜í™”"
    results = vector_db.similarity_search(query, k=5)

    print("\nðŸ“Œ [í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼]")
    for i, doc in enumerate(results, 1):
        print(f"{i}. {doc.page_content.splitlines()[0]}")  # ì œëª©ë§Œ ì¶œë ¥

def inspect_vector_db(vector_db):
    """
    ì €ìž¥ëœ Chroma ë²¡í„° DB ë‚´ë¶€ ë¬¸ì„œ ë° ë©”íƒ€ë°ì´í„°ë¥¼ í™•ì¸í•˜ê³ 
    ì¤‘ë³µ ì œëª© ì—¬ë¶€ë„ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    print("ðŸ“¦ ë²¡í„° DB ë¬¸ì„œ ê²€ì‚¬ ì¤‘...\n")

    all_docs = vector_db.get(include=["documents", "metadatas"])
    docs = all_docs["documents"]
    metas = all_docs["metadatas"]

    title_counts = {}
    for doc, meta in zip(docs, metas):
        title = meta.get("title", "ì œëª© ì—†ìŒ")
        year = meta.get("year", "ì—°ë„ ì—†ìŒ")
        key = f"{title} ({year})"
        title_counts[key] = title_counts.get(key, 0) + 1

    print(f"âœ… ì´ ë¬¸ì„œ ìˆ˜: {len(docs)}")
    print(f"âœ… ê³ ìœ  ì œëª© ìˆ˜: {len(title_counts)}\n")

    # ì¤‘ë³µ ì¶œë ¥
    duplicates = {k: v for k, v in title_counts.items() if v > 1}
    if duplicates:
        print("âš ï¸ ì¤‘ë³µ ì œëª©ë“¤:")
        for k, v in duplicates.items():
            print(f"  - {k}: {v}ê°œ")
    else:
        print("âœ… ì¤‘ë³µ ì—†ìŒ")

    # ì˜ˆì‹œë¡œ ì²˜ìŒ 5ê°œ ì¶œë ¥
    print("\nðŸ“‘ ìƒ˜í”Œ ë¬¸ì„œ 5ê°œ:")
    for i, (doc, meta) in enumerate(zip(docs, metas)):
        if i >= 5: break
        print(f"{i+1}. {meta.get('title')} ({meta.get('year')}) - {meta.get('mood_labels')}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    json_path = "./movies.json"
    persist_dir = "./movie_vectorDB"
    prepare_chroma_movie_db(json_path, persist_dir)

    print("\nðŸ§ª ë²¡í„° DB ë‚´ìš© ê²€ì‚¬:")
    vector_db = Chroma(
        persist_directory=persist_dir,
        embedding_function=HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-sts")
    )
    inspect_vector_db(vector_db)